{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3980041,"sourceType":"datasetVersion","datasetId":2361804}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import DataLoader\nfrom transformers import ViTFeatureExtractor, ViTForImageClassification\n\n# Define dataset paths\ndata_dir = \"/kaggle/input/nike-adidas-shoes-for-image-classification-dataset\"\n\n#/kaggle/input/time-image-datasetclassification\n##/kaggle/input/pets-facial-expression-dataset/Master Folder\n\n# Define transformations for data preprocessing and augmentation\ntrain_transform = transforms.Compose([\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\nval_test_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Create datasets and data loaders\ntrain_dataset = datasets.ImageFolder(os.path.join(data_dir, \"train\"), transform=train_transform)\nvalid_dataset = datasets.ImageFolder(os.path.join(data_dir, \"validation\"), transform=val_test_transform)\ntest_dataset = datasets.ImageFolder(os.path.join(data_dir, \"test\"), transform=val_test_transform)\n\nbatch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=batch_size)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)\n\n# Load the pre-trained ViT model\nmodel_name = \"google/vit-base-patch16-224-in21k\"\nfeature_extractor = ViTFeatureExtractor(model_name)\nmodel = ViTForImageClassification.from_pretrained(model_name, num_labels=len(train_dataset.classes))\n\n# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), lr=0.0001)  # Adjust learning rate\n\n# Learning rate scheduler with warm-up\nscheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001, total_steps=len(train_loader) * 20)\n\n# Training loop\nnum_epochs = 10\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nbest_validation_accuracy = 0.0\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    \n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs.logits, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n    \n    # Validation loop\n    model.eval()\n    with torch.no_grad():\n        correct = 0\n        total = 0\n        for inputs, labels in valid_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.logits, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n        \n        validation_accuracy = 100 * correct / total\n        \n        # Save the model if validation accuracy improved\n        if validation_accuracy > best_validation_accuracy:\n            best_validation_accuracy = validation_accuracy\n            torch.save(model.state_dict(), \"best_model.pth\")\n    \n    print(f\"Epoch [{epoch + 1}/{num_epochs}] \"\n          f\"Loss: {running_loss / len(train_loader):.4f} \"\n          f\"Validation Accuracy: {validation_accuracy:.2f}%\")\n    \n    # Adjust learning rate\n    scheduler.step()\n\n# Load the best model for testing\nmodel.load_state_dict(torch.load(\"best_model.pth\"))\n\n# Testing the model\nmodel.eval()\ntest_correct = 0\ntest_total = 0\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        _, predicted = torch.max(outputs.logits, 1)\n        test_total += labels.size(0)\n        test_correct += (predicted == labels).sum().item()\n\ntest_accuracy = 100 * test_correct / test_total\nprint(f\"Test Accuracy: {test_accuracy:.2f}%\")","metadata":{"_uuid":"39530c89-10de-450a-9576-f223221fb050","_cell_guid":"2d89054a-2507-4a7d-bf23-1ee168f8bc9f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-08-13T13:36:39.757261Z","iopub.execute_input":"2024-08-13T13:36:39.757647Z","iopub.status.idle":"2024-08-13T13:38:55.470410Z","shell.execute_reply.started":"2024-08-13T13:36:39.757610Z","shell.execute_reply":"2024-08-13T13:38:55.469428Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"a03076a6-5a79-4890-85cd-20ed77524722","_cell_guid":"ca769541-c397-45c7-9b94-dd89b79ef39b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}